                                                                      
                                                                      
                                                                      
                                                                      
          Let’s go through this code:                                 
                                                                      
           • The constructor creates the DNN with five dense hidden layers and one dense
            output layer.                                             
           • The build() method creates an extra dense layer which will be used to recon‐
            struct the inputs of the model. It must be created here because its number of units
            must be equal to the number of inputs, and this number is unknown before the
            build() method is called.                                 
                                                                      
           • The call() method processes the inputs through all five hidden layers, then
            passes the result through the reconstruction layer, which produces the recon‐
            struction.                                                
           • Then the call() method computes the reconstruction loss (the mean squared
            difference between the reconstruction and the inputs), and adds it to the model’s
            list of losses using the add_loss() method.11 Notice that we scale down the
            reconstruction loss by multiplying it by 0.05 (this is a hyperparameter you can
            tune). This ensures that the reconstruction loss does not dominate the main loss.
           • Finally, the call() method passes the output of the hidden layers to the output
            layer and returns its output.                             
                                                                      
          Similarly, you can add a custom metric based on model internals by computing it in
          any way you want, as long as the result is the output of a metric object. For example,
          you can create a keras.metrics.Mean object in the constructor, then call it in the
          call() method, passing it the recon_loss, and finally add it to the model by calling
          the model’s add_metric() method. This way, when you train the model, Keras will
          display both the mean loss over each epoch (the loss is the sum of the main loss plus
          0.05 times the reconstruction loss) and the mean reconstruction error over each
          epoch. Both will go down during training:                   
            Epoch 1/5                                                 
            11610/11610 [=============] [...] loss: 4.3092 - reconstruction_error: 1.7360
            Epoch 2/5                                                 
            11610/11610 [=============] [...] loss: 1.1232 - reconstruction_error: 0.8964
            [...]                                                     
          In over 99% of cases, everything we have discussed so far will be sufficient to imple‐
          ment whatever model you want to build, even with complex architectures, losses, and
          metrics. However, in some rare cases you may need to customize the training loop
                                                                      
                                                                      
                                                                      
                                                                      
          11 You can also call add_loss() on any layer inside the model, as the model recursively gathers losses from all of
           its layers.                                                