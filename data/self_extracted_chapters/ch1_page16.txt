                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
          Figure 1-13. In online learning, a model is trained and launched into production, and
          then it keeps learning as new data comes in                 
                                                                      
          Online learning is great for systems that receive data as a continuous flow (e.g., stock
          prices) and need to adapt to change rapidly or autonomously. It is also a good option
          if you have limited computing resources: once an online learning system has learned
          about new data instances, it does not need them anymore, so you can discard them
          (unless you want to be able to roll back to a previous state and “replay” the data). This
          can save a huge amount of space.                            
          Online learning algorithms can also be used to train systems on huge datasets that
          cannot fit in one machine’s main memory (this is called out-of-core learning). The
          algorithm loads part of the data, runs a training step on that data, and repeats the
          process until it has run on all of the data (see Figure 1-14).
                                                                      
                                                                      
                   Out-of-core learning is usually done offline (i.e., not on the live
                   system), so online learning can be a confusing name. Think of it as
                   incremental learning.                              
                                                                      
                                                                      
          One important parameter of online learning systems is how fast they should adapt to
          changing data: this is called the learning rate. If you set a high learning rate, then your
          system will rapidly adapt to new data, but it will also tend to quickly forget the old
          data (you don’t want a spam filter to flag only the latest kinds of spam it was shown).
          Conversely, if you set a low learning rate, the system will have more inertia; that is, it
          will learn more slowly, but it will also be less sensitive to noise in the new data or to
          sequences of nonrepresentative data points (outliers).      
                                                                      
                                                                      
                                                                      