                                                                      
                                                                      
                                                                      
                                                                      
          This implementation relies on the optimizer’s initial learning rate (contrary to the
          previous implementation), so make sure to set it appropriately.
                                                                      
          When you save a model, the optimizer and its learning rate get saved along with it.
          This means that with this new schedule function, you could just load a trained model
          and continue training where it left off, no problem. Things are not so simple if your
          schedule function uses the epoch argument, however: the epoch does not get saved,
          and it gets reset to 0 every time you call the fit() method. If you were to continue
          training a model where it left off, this could lead to a very large learning rate, which
          would likely damage your model’s weights. One solution is to manually set the fit()
          method’s initial_epoch argument so the epoch starts at the right value.
          For piecewise constant scheduling, you can use a schedule function like the following
          one (as earlier, you can define a more general function if you want; see the “Piecewise
          Constant Scheduling” section of the notebook for an example), then create a Lear
          ningRateScheduler callback with this function and pass it to the fit() method, just
          like we did for exponential scheduling:                     
            def piecewise_constant_fn(epoch):                         
               if epoch < 5:                                          
                 return 0.01                                          
               elif epoch < 15:                                       
                 return 0.005                                         
               else:                                                  
                 return 0.001                                         
          For performance scheduling, use the ReduceLROnPlateau callback. For example, if
          you pass the following callback to the fit() method, it will multiply the learning rate
          by 0.5 whenever the best validation loss does not improve for five consecutive epochs
          (other options are available; please check the documentation for more details):
            lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)
          Lastly, tf.keras offers an alternative way to implement learning rate scheduling: define
          the learning rate using one of the schedules available in keras.optimizers.sched
          ules, then pass this learning rate to any optimizer. This approach updates the learn‐
          ing rate at each step rather than at each epoch. For example, here is how to implement
          the same exponential schedule as the exponential_decay_fn() function we defined
          earlier:                                                    
            s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)
            learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)
            optimizer = keras.optimizers.SGD(learning_rate)           
          This is nice and simple, plus when you save the model, the learning rate and its
          schedule (including its state) get saved as well. This approach, however, is not part of
          the Keras API; it is specific to tf.keras.                  
                                                                      
                                                                      