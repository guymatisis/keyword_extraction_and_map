                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
            Equation 16-1. Attention mechanisms                       
                                                                      
                   = ∑α                                               
                 t    t,i i                                           
                    i                                                 
                     exp e                                            
                         t,i                                          
             with α =                                                 
                 t,i                                                  
                    ∑ exp e                                           
                     i′   t,i′                                        
                      ⊺          dot                                  
                      t i                                             
             and e =  ⊺          general                              
                 t,i  t   i                                           
                     ⊺ tanh   ;  concat                               
                             t i                                      
          Here is how you can add Luong attention to an Encoder–Decoder model using Ten‐
          sorFlow Addons:                                             
            attention_mechanism = tfa.seq2seq.attention_wrapper.LuongAttention(
               units, encoder_state, memory_sequence_length=encoder_sequence_length)
            attention_decoder_cell = tfa.seq2seq.attention_wrapper.AttentionWrapper(
               decoder_cell, attention_mechanism, attention_layer_size=n_units)
          We simply wrap the decoder cell in an AttentionWrapper, and we provide the desired
          attention mechanism (Luong attention in this example).      
          Visual Attention                                            
          Attention mechanisms are now used for a variety of purposes. One of their first appli‐
          cations beyond NMT was in generating image captions using visual attention:17 a
          convolutional neural network first processes the image and outputs some feature
          maps, then a decoder RNN equipped with an attention mechanism generates the cap‐
          tion, one word at a time. At each decoder time step (each word), the decoder uses the
          attention model to focus on just the right part of the image. For example, in
          Figure 16-7, the model generated the caption “A woman is throwing a frisbee in a
          park,” and you can see what part of the input image the decoder focused its attention
          on when it was about to output the word “frisbee”: clearly, most of its attention was
          focused on the frisbee.                                     
                                                                      
                                                                      
                                                                      
          17 Kelvin Xu et al., “Show, Attend and Tell: Neural Image Caption Generation with Visual Attention,” Proceedings
           of the 32nd International Conference on Machine Learning (2015): 2048–2057.