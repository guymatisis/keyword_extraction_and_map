                                                                      
                                                                      
                                                                      
                                                                      
                   To view the generated function’s source code, you can call tf.auto
                   graph.to_code(sum_squares.python_function). The code is not
                   meant to be pretty, but it can sometimes help for debugging.
                                                                      
                                                                      
          TF Function Rules                                           
                                                                      
          Most of the time, converting a Python function that performs TensorFlow operations
          into a TF Function is trivial: decorate it with @tf.function or let Keras take care of it
          for you. However, there are a few rules to respect:         
                                                                      
           • If you call any external library, including NumPy or even the standard library,
            this call will run only during tracing; it will not be part of the graph. Indeed, a
            TensorFlow graph can only include TensorFlow constructs (tensors, operations,
            variables, datasets, and so on). So, make sure you use tf.reduce_sum() instead
            of np.sum(), tf.sort() instead of the built-in sorted() function, and so on
            (unless you really want the code to run only during tracing). This has a few addi‐
            tional implications:                                      
             —If you define a TF Function f(x) that just returns np.random.rand(), a ran‐
              dom number will only be generated when the function is traced, so f(tf.con
              stant(2.)) and f(tf.constant(3.)) will return the same random number,
              but f(tf.constant([2., 3.])) will return a different one. If you replace
              np.random.rand() with tf.random.uniform([]), then a new random num‐
              ber will be generated upon every call, since the operation will be part of the
              graph.                                                  
             —If your non-TensorFlow code has side effects (such as logging something or
              updating a Python counter), then you should not expect those side effects to
              occur every time you call the TF Function, as they will only occur when the
              function is traced.                                     
             —You can wrap arbitrary Python code in a tf.py_function() operation, but
              doing so will hinder performance, as TensorFlow will not be able to do any
              graph optimization on this code. It will also reduce portability, as the graph
              will only run on platforms where Python is available (and where the right
              libraries are installed).                               
                                                                      
           • You can call other Python functions or TF Functions, but they should follow the
            same rules, as TensorFlow will capture their operations in the computation
            graph. Note that these other functions do not need to be decorated with
            @tf.function.                                             
           • If the function creates a TensorFlow variable (or any other stateful TensorFlow
            object, such as a dataset or a queue), it must do so upon the very first call, and
            only then, or else you will get an exception. It is usually preferable to create