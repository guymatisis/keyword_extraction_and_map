                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
          Figure 15-8. Forecasting 10 steps ahead, 1 step at a time   
                                                                      
          The second option is to train an RNN to predict all 10 next values at once. We can
          still use a sequence-to-vector model, but it will output 10 values instead of 1. How‐
          ever, we first need to change the targets to be vectors containing the next 10 values:
            series = generate_time_series(10000, n_steps + 10)        
            X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]
            X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]
            X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]
          Now we just need the output layer to have 10 units instead of 1:
            model = keras.models.Sequential([                         
               keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
               keras.layers.SimpleRNN(20),                            
               keras.layers.Dense(10)                                 
            ])                                                        
          After training this model, you can predict the next 10 values at once very easily:
            Y_pred = model.predict(X_new)                             
          This model works nicely: the MSE for the next 10 time steps is about 0.008. That’s
          much better than the linear model. But we can still do better: indeed, instead of train‐
          ing the model to forecast the next 10 values only at the very last time step, we can
          train it to forecast the next 10 values at each and every time step. In other words, we
          can turn this sequence-to-vector RNN into a sequence-to-sequence RNN. The advan‐
          tage of this technique is that the loss will contain a term for the output of the RNN at
          each and every time step, not just the output at the last time step. This means there
          will be many more error gradients flowing through the model, and they won’t have to
          flow only through time; they will also flow from the output of each time step. This
          will both stabilize and speed up training.                  
                                                                      