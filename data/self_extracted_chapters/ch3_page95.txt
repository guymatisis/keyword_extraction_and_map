                                                                      
                                                                      
                                                                      
                                                                      
            from sklearn.metrics import precision_recall_curve        
                                                                      
            precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)
          Finally, use Matplotlib to plot precision and recall as functions of the threshold value
          (Figure 3-4):                                               
            def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):
               plt.plot(thresholds, precisions[:-1], "b--", label="Precision")
               plt.plot(thresholds, recalls[:-1], "g-", label="Recall")
               [...] # highlight the threshold and add the legend, axis label, and grid
            plot_precision_recall_vs_threshold(precisions, recalls, thresholds)
            plt.show()                                                
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
          Figure 3-4. Precision and recall versus the decision threshold
                                                                      
                   You may wonder why the precision curve is bumpier than the recall
                   curve in Figure 3-4. The reason is that precision may sometimes go
                   down when you raise the threshold (although in general it will go
                   up). To understand why, look back at Figure 3-3 and notice what
                   happens when you start from the central threshold and move it just
                   one digit to the right: precision goes from 4/5 (80%) down to 3/4
                   (75%). On the other hand, recall can only go down when the thres‚Äê
                   hold is increased, which explains why its curve looks smooth.
                                                                      
          Another way to select a good precision/recall trade-off is to plot precision directly
          against recall, as shown in Figure 3-5 (the same threshold as earlier is highlighted).
                                                                      
                                                                      
                                                                      
                                                                      