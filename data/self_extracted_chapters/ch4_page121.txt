                                                                      
                                                                      
                                                                      
                                                                      
          As you can see, on the left the Gradient Descent algorithm goes straight toward the
          minimum, thereby reaching it quickly, whereas on the right it first goes in a direction
          almost orthogonal to the direction of the global minimum, and it ends with a long
          march down an almost flat valley. It will eventually reach the minimum, but it will
          take a long time.                                           
                                                                      
                   When using Gradient Descent, you should ensure that all features
                   have a similar scale (e.g., using Scikit-Learn’s StandardScaler
                   class), or else it will take much longer to converge.
                                                                      
                                                                      
          This diagram also illustrates the fact that training a model means searching for a
          combination of model parameters that minimizes a cost function (over the training
          set). It is a search in the model’s parameter space: the more parameters a model has,
          the more dimensions this space has, and the harder the search is: searching for a nee‐
          dle in a 300-dimensional haystack is much trickier than in 3 dimensions. Fortunately,
          since the cost function is convex in the case of Linear Regression, the needle is simply
          at the bottom of the bowl.                                  
                                                                      
          Batch Gradient Descent                                      
                                                                      
          To implement Gradient Descent, you need to compute the gradient of the cost func‐
          tion with regard to each model parameter θ. In other words, you need to calculate
                                    j                                 
          how much the cost function will change if you change θ just a little bit. This is called
                                           j                          
          a partial derivative. It is like asking “What is the slope of the mountain under my feet
          if I face east?” and then asking the same question facing north (and so on for all other
          dimensions, if you can imagine a universe with more than three dimensions). Equa‐
          tion 4-5 computes the partial derivative of the cost function with regard to parameter
          θ, noted ∂ MSE(θ) / ∂θ.                                     
           j           j                                              
            Equation 4-5. Partial derivatives of the cost function    
                      m                                               
             ∂ MSE θ = 2 ∑ θ ⊺ x i −y i x i                           
            ∂θ      m           j                                     
              j      i=1                                              
          Instead of computing these partial derivatives individually, you can use Equation 4-6
          to compute them all in one go. The gradient vector, noted ∇ MSE(θ), contains all the
                                             θ                        
          partial derivatives of the cost function (one for each model parameter).
                                                                      