                                                                      
                                                                      
                                                                      
                                                                      
          We can obviously call this function with a Python value, such as an int or a float, or
          we can call it with a tensor:                               
                                                                      
            >>> cube(2)                                               
            8                                                         
            >>> cube(tf.constant(2.0))                                
            <tf.Tensor: id=18634148, shape=(), dtype=float32, numpy=8.0>
          Now, let’s use tf.function() to convert this Python function to a TensorFlow
          Function:                                                   
            >>> tf_cube = tf.function(cube)                           
            >>> tf_cube                                               
            <tensorflow.python.eager.def_function.Function at 0x1546fc080>
          This TF Function can then be used exactly like the original Python function, and it
          will return the same result (but as tensors):               
            >>> tf_cube(2)                                            
            <tf.Tensor: id=18634201, shape=(), dtype=int32, numpy=8>  
            >>> tf_cube(tf.constant(2.0))                             
            <tf.Tensor: id=18634211, shape=(), dtype=float32, numpy=8.0>
          Under the hood, tf.function() analyzed the computations performed by the cube()
          function and generated an equivalent computation graph! As you can see, it was
          rather painless (we will see how this works shortly). Alternatively, we could have used
          tf.function as a decorator; this is actually more common:   
            @tf.function                                              
            def tf_cube(x):                                           
               return x ** 3                                          
          The original Python function is still available via the TF Function’s python_function
          attribute, in case you ever need it:                        
            >>> tf_cube.python_function(2)                            
            8                                                         
          TensorFlow optimizes the computation graph, pruning unused nodes, simplifying
          expressions (e.g., 1 + 2 would get replaced with 3), and more. Once the optimized
          graph is ready, the TF Function efficiently executes the operations in the graph, in the
          appropriate order (and in parallel when it can). As a result, a TF Function will usually
          run much faster than the original Python function, especially if it performs complex
          computations.15 Most of the time you will not really need to know more than that:
          when you want to boost a Python function, just transform it into a TF Function.
          That’s all!                                                 
                                                                      
                                                                      
                                                                      
          15 However, in this trivial example, the computation graph is so small that there is nothing at all to optimize, so
           tf_cube() actually runs much slower than cube().           