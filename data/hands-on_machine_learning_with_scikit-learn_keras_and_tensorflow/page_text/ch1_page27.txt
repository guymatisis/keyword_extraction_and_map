                                                                      
                                                                      
                                                                      
                                                                      
          Irrelevant Features                                         
                                                                      
          As the saying goes: garbage in, garbage out. Your system will only be capable of learn‐
          ing if the training data contains enough relevant features and not too many irrelevant
          ones. A critical part of the success of a Machine Learning project is coming up with a
          good set of features to train on. This process, called feature engineering, involves the
          following steps:                                            
                                                                      
           • Feature selection (selecting the most useful features to train on among existing
            features)                                                 
           • Feature extraction (combining existing features to produce a more useful one—as
            we saw earlier, dimensionality reduction algorithms can help)
           • Creating new features by gathering new data              
                                                                      
          Now that we have looked at many examples of bad data, let’s look at a couple of exam‐
          ples of bad algorithms.                                     
          Overfitting the Training Data                               
                                                                      
          Say you are visiting a foreign country and the taxi driver rips you off. You might be
          tempted to say that all taxi drivers in that country are thieves. Overgeneralizing is
          something that we humans do all too often, and unfortunately machines can fall into
          the same trap if we are not careful. In Machine Learning this is called overfitting: it
          means that the model performs well on the training data, but it does not generalize
          well.                                                       
                                                                      
          Figure 1-22 shows an example of a high-degree polynomial life satisfaction model
          that strongly overfits the training data. Even though it performs much better on the
          training data than the simple linear model, would you really trust its predictions?
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
          Figure 1-22. Overfitting the training data                  
                                                                      
                                                                      
                                                                      