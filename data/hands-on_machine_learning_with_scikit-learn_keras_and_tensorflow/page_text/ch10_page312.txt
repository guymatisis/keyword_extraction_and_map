                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
          Figure 10-16. Handling multiple outputs, in this example to add an auxiliary output for
          regularization                                              
                                                                      
          Adding extra outputs is quite easy: just connect them to the appropriate layers and
          add them to your model’s list of outputs. For example, the following code builds the
          network represented in Figure 10-16:                        
            [...] # Same as above, up to the main output layer        
            output = keras.layers.Dense(1, name="main_output")(concat)
            aux_output = keras.layers.Dense(1, name="aux_output")(hidden2)
            model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])
          Each output will need its own loss function. Therefore, when we compile the model,
          we should pass a list of losses20 (if we pass a single loss, Keras will assume that the
          same loss must be used for all outputs). By default, Keras will compute all these losses
          and simply add them up to get the final loss used for training. We care much more
          about the main output than about the auxiliary output (as it is just used for regulari‐
          zation), so we want to give the main output’s loss a much greater weight. Fortunately,
          it is possible to set all the loss weights when compiling the model:
            model.compile(loss=["mse", "mse"], loss_weights=[0.9, 0.1], optimizer="sgd")
          Now when we train the model, we need to provide labels for each output. In this
          example, the main output and the auxiliary output should try to predict the same
          thing, so they should use the same labels. So instead of passing y_train, we need to
          pass (y_train, y_train) (and the same goes for y_valid and y_test):
            history = model.fit(                                      
               [X_train_A, X_train_B], [y_train, y_train], epochs=20, 
               validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))
                                                                      
                                                                      
                                                                      
          20 Alternatively, you can pass a dictionary that maps each output name to the corresponding loss. Just like for
           the inputs, this is useful when there are multiple outputs, to avoid getting the order wrong. The loss weights
           and metrics (discussed shortly) can also be set using dictionaries.