                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
          Regression                                                  
                                                                      
          Decision Trees are also capable of performing regression tasks. Let’s build a regres‐
          sion tree using Scikit-Learn’s DecisionTreeRegressor class, training it on a noisy
          quadratic dataset with max_depth=2:                         
                                                                      
            from sklearn.tree import DecisionTreeRegressor            
            tree_reg = DecisionTreeRegressor(max_depth=2)             
            tree_reg.fit(X, y)                                        
          The resulting tree is represented in Figure 6-4.            
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
          Figure 6-4. A Decision Tree for regression                  
                                                                      
          This tree looks very similar to the classification tree you built earlier. The main differ‐
          ence is that instead of predicting a class in each node, it predicts a value. For example,
          suppose you want to make a prediction for a new instance with x = 0.6. You traverse
                                                1                     
          the tree starting at the root, and you eventually reach the leaf node that predicts
          value=0.111. This prediction is the average target value of the 110 training instances
          associated with this leaf node, and it results in a mean squared error equal to 0.015
          over these 110 instances.                                   
          This model’s predictions are represented on the left in Figure 6-5. If you set
          max_depth=3, you get the predictions represented on the right. Notice how the pre‐
          dicted value for each region is always the average target value of the instances in that
          region. The algorithm splits each region in a way that makes most training instances
          as close as possible to that predicted value.               
                                                                      