                                                                      
                                                                      
                                                                      
                                                                      
          groundbreaking paper10 that introduced the backpropagation training algorithm,
          which is still used today. In short, it is Gradient Descent (introduced in Chapter 4)
          using an efficient technique for computing the gradients automatically:11 in just two
          passes through the network (one forward, one backward), the backpropagation algo‐
          rithm is able to compute the gradient of the network’s error with regard to every sin‐
          gle model parameter. In other words, it can find out how each connection weight and
          each bias term should be tweaked in order to reduce the error. Once it has these gra‐
          dients, it just performs a regular Gradient Descent step, and the whole process is
          repeated until the network converges to the solution.       
                                                                      
                   Automatically computing gradients is called automatic differentia‐
                   tion, or autodiff. There are various autodiff techniques, with differ‐
                   ent pros and cons. The one used by backpropagation is called
                   reverse-mode autodiff. It is fast and precise, and is well suited when
                   the function to differentiate has many variables (e.g., connection
                   weights) and few outputs (e.g., one loss). If you want to learn more
                   about autodiff, check out Appendix D.              
                                                                      
          Let’s run through this algorithm in a bit more detail:      
           • It handles one mini-batch at a time (for example, containing 32 instances each),
            and it goes through the full training set multiple times. Each pass is called an
            epoch.                                                    
           • Each mini-batch is passed to the network’s input layer, which sends it to the first
            hidden layer. The algorithm then computes the output of all the neurons in this
            layer (for every instance in the mini-batch). The result is passed on to the next
            layer, its output is computed and passed to the next layer, and so on until we get
            the output of the last layer, the output layer. This is the forward pass: it is exactly
            like making predictions, except all intermediate results are preserved since they
            are needed for the backward pass.                         
                                                                      
           • Next, the algorithm measures the network’s output error (i.e., it uses a loss func‐
            tion that compares the desired output and the actual output of the network, and
            returns some measure of the error).                       
           • Then it computes how much each output connection contributed to the error.
            This is done analytically by applying the chain rule (perhaps the most fundamen‐
            tal rule in calculus), which makes this step fast and precise.
                                                                      
                                                                      
          10 David Rumelhart et al. “Learning Internal Representations by Error Propagation,” (Defense Technical Infor‐
           mation Center technical report, September 1985).           
          11 This technique was actually independently invented several times by various researchers in different fields,
           starting with Paul Werbos in 1974.                         