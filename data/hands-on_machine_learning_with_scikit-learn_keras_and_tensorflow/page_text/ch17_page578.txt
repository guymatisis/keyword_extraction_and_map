                                                                      
                                                                      
                                                                      
                                                                      
            tied_decoder = keras.models.Sequential([                  
               DenseTranspose(dense_2, activation="selu"),            
               DenseTranspose(dense_1, activation="sigmoid"),         
               keras.layers.Reshape([28, 28])                         
            ])                                                        
            tied_ae = keras.models.Sequential([tied_encoder, tied_decoder])
          This model achieves a very slightly lower reconstruction error than the previous
          model, with almost half the number of parameters.           
                                                                      
          Training One Autoencoder at a Time                          
                                                                      
          Rather than training the whole stacked autoencoder in one go like we just did, it is
          possible to train one shallow autoencoder at a time, then stack all of them into a sin‐
          gle stacked autoencoder (hence the name), as shown in Figure 17-7. This technique is
          not used as much these days, but you may still run into papers that talk about “greedy
          layerwise training,” so it’s good to know what it means.    
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
          Figure 17-7. Training one autoencoder at a time             
                                                                      
          During the first phase of training, the first autoencoder learns to reconstruct the
          inputs. Then we encode the whole training set using this first autoencoder, and this
          gives us a new (compressed) training set. We then train a second autoencoder on this
          new dataset. This is the second phase of training. Finally, we build a big sandwich
          using all these autoencoders, as shown in Figure 17-7 (i.e., we first stack the hidden
          layers of each autoencoder, then the output layers in reverse order). This gives us the
          final stacked autoencoder (see the “Training One Autoencoder at a Time” section in
          the notebook for an implementation). We could easily train more autoencoders this
          way, building a very deep stacked autoencoder.              
                                                                      