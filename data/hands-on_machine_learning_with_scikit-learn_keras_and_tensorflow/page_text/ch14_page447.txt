<i>Figure</i> <i>14-1.</i> <i>Biological</i> <i>neurons</i> <i>in</i> <i>the</i> <i>visual</i> <i>cortex</i> <i>respond</i> <i>to</i> <i>specific</i> <i>patterns</i> <i>in</i> <i>small</i>
<i>regions</i> <i>of</i> <i>the</i> <i>visual</i> <i>field</i> <i>called</i> <i>receptive</i> <i>fields;</i> <i>as</i> <i>the</i> <i>visual</i> <i>signal</i> <i>makes</i> <i>its</i> <i>way</i>
<i>through</i> <i>consecutive</i> <i>brain</i> <i>modules,</i> <i>neurons</i> <i>respond</i> <i>to</i> <i>more</i> <i>complex</i> <i>patterns</i> <i>in</i> <i>larger</i>
<i>receptive</i> <i>fields.</i>
These studies of the visual cortex inspired the neocognitron,4 introduced in 1980,
which gradually evolved into what we now call <i>convolutional</i> <i>neural</i> <i>networks.</i> An
important milestone was a 1998 paper 5 by Yann LeCun et al. that introduced the
famous <i>LeNet-5</i> architecture, widely used by banks to recognize handwritten check
numbers. This architecture has some building blocks that you already know, such as
fully connected layers and sigmoid activation functions, but it also introduces two
new building blocks: <i>convolutional</i> <i>layers</i> and <i>pooling</i> <i>layers.</i> Let’s look at them now.
Why not simply use a deep neural network with fully connected
layers for image recognition tasks? Unfortunately, although this
works fine for small images (e.g., MNIST), it breaks down for
larger images because of the huge number of parameters it
requires. For example, a 100 × 100–pixel image has 10,000 pixels,
and if the first layer has just 1,000 neurons (which already severely
restricts the amount of information transmitted to the next layer),
this means a total of 10 million connections. And that’s just the first
layer. CNNs solve this problem using partially connected layers and
weight sharing.
4 KunihikoFukushima,“Neocognitron:ASelf-OrganizingNeuralNetworkModelforaMechanismofPattern
RecognitionUnaffectedbyShiftinPosition,”BiologicalCybernetics36(1980):193–202.
5 YannLeCunetal.,“Gradient-BasedLearningAppliedtoDocumentRecognition,”ProceedingsoftheIEEE86,
no.11(1998):2278–2324.