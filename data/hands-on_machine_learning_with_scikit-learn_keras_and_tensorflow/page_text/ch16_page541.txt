nnlm-en-dim50
For example, let’s use the sentence embedding module, version 1, in
our sentiment analysis model:
<b>import</b> <b>tensorflow_hub</b> <b>as</b> <b>hub</b>
model = keras.Sequential([
hub.KerasLayer("https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1",
dtype=tf.string, input_shape=[], output_shape=[50]),
keras.layers.Dense(128, activation="relu"),
keras.layers.Dense(1, activation="sigmoid")
])
model.compile(loss="binary_crossentropy", optimizer="adam",
metrics=["accuracy"])
The hub.KerasLayer layer downloads the module from the given URL. This particu‐
lar module is a <i>sentence</i> <i>encoder:</i> it takes strings as input and encodes each one as a
single vector (in this case, a 50-dimensional vector). Internally, it parses the string
(splitting words on spaces) and embeds each word using an embedding matrix that
was pretrained on a huge corpus: the Google News 7B corpus (seven billion words
long!). Then it computes the mean of all the word embeddings, and the result is the
Dense
sentence embedding.9 We can then add two simple layers to create a good sen‐
timent analysis model. By default, a hub.KerasLayer is not trainable, but you can set
trainable=True
when creating it to change that so that you can fine-tune it for your
task.
Not all TF Hub modules support TensorFlow 2, so make sure you
choose a module that does.
Next, we can just load the IMDb reviews dataset—no need to preprocess it (except for
batching and prefetching)—and directly train the model:
datasets, info = tfds.load("imdb_reviews", as_supervised=True, with_info=True)
train_size = info.splits["train"].num_examples
batch_size = 32
train_set = datasets["train"].batch(batch_size).prefetch(1)
history = model.fit(train_set, epochs=5)
Note that the last part of the TF Hub module URL specified that we wanted version 1
of the model. This versioning ensures that if a new module version is released, it will
not break our model. Conveniently, if you just enter this URL in a web browser, you
9 Tobeprecise,thesentenceembeddingisequaltothemeanwordembeddingmultipliedbythesquarerootof
thenumberofwordsinthesentence.Thiscompensatesforthefactthatthemeanofnvectorsgetsshorteras
<i>ngrows.</i>