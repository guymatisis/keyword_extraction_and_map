                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
          Figure 17-16. Images generated by the GAN after one epoch of training
          The Difficulties of Training GANs                           
                                                                      
          During training, the generator and the discriminator constantly try to outsmart each
          other, in a zero-sum game. As training advances, the game may end up in a state that
          game theorists call a Nash equilibrium, named after the mathematician John Nash:
          this is when no player would be better off changing their own strategy, assuming the
          other players do not change theirs. For example, a Nash equilibrium is reached when
          everyone drives on the left side of the road: no driver would be better off being the
          only one to switch sides. Of course, there is a second possible Nash equilibrium:
          when everyone drives on the right side of the road. Different initial states and dynam‐
          ics may lead to one equilibrium or the other. In this example, there is a single optimal
          strategy once an equilibrium is reached (i.e., driving on the same side as everyone
          else), but a Nash equilibrium can involve multiple competing strategies (e.g., a preda‐
          tor chases its prey, the prey tries to escape, and neither would be better off changing
          their strategy).                                            
          So how does this apply to GANs? Well, the authors of the paper demonstrated that a
          GAN can only reach a single Nash equilibrium: that’s when the generator produces
          perfectly realistic images, and the discriminator is forced to guess (50% real, 50%
          fake). This fact is very encouraging: it would seem that you just need to train the
          GAN for long enough, and it will eventually reach this equilibrium, giving you a per‐
          fect generator. Unfortunately, it’s not that simple: nothing guarantees that the equili‐
          brium will ever be reached.                                 
                                                                      
                                                                      
                                                                      
                                                                      