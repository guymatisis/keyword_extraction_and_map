When we evaluate the model, Keras will return the total loss, as well as all the individ‐
ual losses:
total_loss, main_loss, aux_loss = model.evaluate(
[X_test_A, X_test_B], [y_test, y_test])
Similarly, the predict() method will return predictions for each output:
y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])
As you can see, you can build any sort of architecture you want quite easily with the
Functional API. Let’s look at one last way you can build Keras models.
<header><largefont><b>Using</b></largefont> <largefont><b>the</b></largefont> <largefont><b>Subclassing</b></largefont> <largefont><b>API</b></largefont> <largefont><b>to</b></largefont> <largefont><b>Build</b></largefont> <largefont><b>Dynamic</b></largefont> <largefont><b>Models</b></largefont></header>
Both the Sequential API and the Functional API are declarative: you start by declar‐
ing which layers you want to use and how they should be connected, and only then
can you start feeding the model some data for training or inference. This has many
advantages: the model can easily be saved, cloned, and shared; its structure can be
displayed and analyzed; the framework can infer shapes and check types, so errors
can be caught early (i.e., before any data ever goes through the model). It’s also fairly
easy to debug, since the whole model is a static graph of layers. But the flip side is just
that: it’s static. Some models involve loops, varying shapes, conditional branching,
and other dynamic behaviors. For such cases, or simply if you prefer a more impera‐
tive programming style, the Subclassing API is for you.
Simply subclass the Model class, create the layers you need in the constructor, and use
call()
them to perform the computations you want in the method. For example, cre‐
WideAndDeepModel
ating an instance of the following class gives us an equivalent
model to the one we just built with the Functional API. You can then compile it, eval‐
uate it, and use it to make predictions, exactly like we just did:
<b>class</b> <b>WideAndDeepModel(keras.Model):</b>
<b>def</b> <b>__init__(self,</b> units=30, activation="relu", **kwargs):
super().__init__(**kwargs) <i>#</i> <i>handles</i> <i>standard</i> <i>args</i> <i>(e.g.,</i> <i>name)</i>
self.hidden1 = keras.layers.Dense(units, activation=activation)
self.hidden2 = keras.layers.Dense(units, activation=activation)
self.main_output = keras.layers.Dense(1)
self.aux_output = keras.layers.Dense(1)
<b>def</b> call(self, inputs):
input_A, input_B = inputs
hidden1 = self.hidden1(input_B)
hidden2 = self.hidden2(hidden1)
concat = keras.layers.concatenate([input_A, hidden2])
main_output = self.main_output(concat)
aux_output = self.aux_output(hidden2)
<b>return</b> main_output, aux_output
model = WideAndDeepModel()