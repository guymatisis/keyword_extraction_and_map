                                                                      
                                                                      
                                                                      
                                                                      
          The biggest difficulty is called mode collapse: this is when the generator’s outputs
          gradually become less diverse. How can this happen? Suppose that the generator gets
          better at producing convincing shoes than any other class. It will fool the discrimina‐
          tor a bit more with shoes, and this will encourage it to produce even more images of
          shoes. Gradually, it will forget how to produce anything else. Meanwhile, the only
          fake images that the discriminator will see will be shoes, so it will also forget how to
          discriminate fake images of other classes. Eventually, when the discriminator man‐
          ages to discriminate the fake shoes from the real ones, the generator will be forced to
          move to another class. It may then become good at shirts, forgetting about shoes, and
          the discriminator will follow. The GAN may gradually cycle across a few classes,
          never really becoming very good at any of them.             
          Moreover, because the generator and the discriminator are constantly pushing against
          each other, their parameters may end up oscillating and becoming unstable. Training
          may begin properly, then suddenly diverge for no apparent reason, due to these insta‐
          bilities. And since many factors affect these complex dynamics, GANs are very sensi‐
          tive to the hyperparameters: you may have to spend a lot of effort fine-tuning them.
                                                                      
          These problems have kept researchers very busy since 2014: many papers were pub‐
          lished on this topic, some proposing new cost functions11 (though a 2018 paper12 by
          Google researchers questions their efficiency) or techniques to stabilize training or to
          avoid the mode collapse issue. For example, a popular technique called experience
          replay consists in storing the images produced by the generator at each iteration in a
          replay buffer (gradually dropping older generated images) and training the discrimi‐
          nator using real images plus fake images drawn from this buffer (rather than just fake
          images produced by the current generator). This reduces the chances that the dis‐
          criminator will overfit the latest generator’s outputs. Another common technique is
          called mini-batch discrimination: it measures how similar images are across the batch
          and provides this statistic to the discriminator, so it can easily reject a whole batch of
          fake images that lack diversity. This encourages the generator to produce a greater
          variety of images, reducing the chance of mode collapse. Other papers simply pro‐
          pose specific architectures that happen to perform well.    
          In short, this is still a very active field of research, and the dynamics of GANs are still
          not perfectly understood. But the good news is that great progress has been made,
          and some of the results are truly astounding! So let’s look at some of the most success‐
          ful architectures, starting with deep convolutional GANs, which were the state of the
          art just a few years ago. Then we will look at two more recent (and more complex)
          architectures.                                              
                                                                      
                                                                      
          11 For a nice comparison of the main GAN losses, check out this great GitHub project by Hwalsuk Lee.
          12 Mario Lucic et al., “Are GANs Created Equal? A Large-Scale Study,” Proceedings of the 32nd International Con‐
           ference on Neural Information Processing Systems (2018): 698–707.