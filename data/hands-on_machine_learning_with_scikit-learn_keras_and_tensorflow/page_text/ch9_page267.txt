                                                                      
                                                                      
                                                                      
                                                                      
          A closely related task is novelty detection: it differs from anomaly detection in that the
          algorithm is assumed to be trained on a “clean” dataset, uncontaminated by outliers,
          whereas anomaly detection does not make this assumption. Indeed, outlier detection
          is often used to clean up a dataset.                        
                                                                      
                   Gaussian mixture models try to fit all the data, including the outli‐
                   ers, so if you have too many of them, this will bias the model’s view
                   of “normality,” and some outliers may wrongly be considered as
                   normal. If this happens, you can try to fit the model once, use it to
                   detect and remove the most extreme outliers, then fit the model
                   again on the cleaned-up dataset. Another approach is to use robust
                   covariance estimation methods (see the EllipticEnvelope class).
                                                                      
          Just like K-Means, the GaussianMixture algorithm requires you to specify the num‐
          ber of clusters. So, how can you find it?                   
          Selecting the Number of Clusters                            
                                                                      
          With K-Means, you could use the inertia or the silhouette score to select the appro‐
          priate number of clusters. But with Gaussian mixtures, it is not possible to use these
          metrics because they are not reliable when the clusters are not spherical or have dif‐
          ferent sizes. Instead, you can try to find the model that minimizes a theoretical infor‐
          mation criterion, such as the Bayesian information criterion (BIC) or the Akaike
          information criterion (AIC), defined in Equation 9-1.       
                                                                      
            Equation 9-1. Bayesian information criterion (BIC) and Akaike information
            criterion (AIC)                                           
            BIC= log m p−2log L                                       
                                                                      
            AIC= 2p−2log L                                            
                                                                      
          In these equations:                                         
                                                                      
           • m is the number of instances, as always.                 
           • p is the number of parameters learned by the model.      
                                                                      
           • L is the maximized value of the likelihood function of the model.
          Both the BIC and the AIC penalize models that have more parameters to learn (e.g.,
          more clusters) and reward models that fit the data well. They often end up selecting
          the same model. When they differ, the model selected by the BIC tends to be simpler
                                                                      
                                                                      
                                                                      