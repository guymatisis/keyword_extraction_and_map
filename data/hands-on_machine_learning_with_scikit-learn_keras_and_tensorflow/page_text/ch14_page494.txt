In a transposed convolutional layer, the stride defines how much
the input will be stretched, not the size of the filter steps, so the
larger the stride, the larger the output (unlike for convolutional lay‐
ers or pooling layers).
<header><largefont><b>TensorFlow</b></largefont> <largefont><b>Convolution</b></largefont> <largefont><b>Operations</b></largefont></header>
TensorFlow also offers a few other kinds of convolutional layers:
keras.layers.Conv1D
Creates a convolutional layer for 1D inputs, such as time series or text (sequences
of letters or words), as we will see in Chapter 15.
keras.layers.Conv3D
Creates a convolutional layer for 3D inputs, such as 3D PET scans.
dilation_rate
Setting the dilation_rate hyperparameter of any convolutional layer to a value
of 2 or more creates an <i>à-trous</i> <i>convolutional</i> <i>layer</i> (“à trous” is French for “with
holes”). This is equivalent to using a regular convolutional layer with a filter dila‐
ted by inserting rows and columns of zeros (i.e., holes). For example, a 1 × 3 filter
equal to [[1,2,3]] may be dilated with a <i>dilation</i> <i>rate</i> of 4, resulting in a <i>dilated</i>
<i>filter</i> of [[1, 0, 0, 0, 2, 0, 0, 0, 3]] . This lets the convolutional layer have
a larger receptive field at no computational price and using no extra parameters.
tf.nn.depthwise_conv2d()
Can be used to create a <i>depthwise</i> <i>convolutional</i> <i>layer</i> (but you need to create the
variables yourself). It applies every filter to every individual input channel inde‐
pendently. Thus, if there are <i>f</i> filters and <i>f</i> input channels, then this will output
<i>n</i> <i>n</i> ′
<i>f</i> × <i>f</i> feature maps.
<i>n</i> <i>n</i> ′
This solution is OK, but still too imprecise. To do better, the authors added skip con‐
nections from lower layers: for example, they upsampled the output image by a factor
of 2 (instead of 32), and they added the output of a lower layer that had this double
resolution. Then they upsampled the result by a factor of 16, leading to a total upsam‐
pling factor of 32 (see Figure 14-28). This recovered some of the spatial resolution
that was lost in earlier pooling layers. In their best architecture, they used a second
similar skip connection to recover even finer details from an even lower layer. In
short, the output of the original CNN goes through the following extra steps: upscale
×2, add the output of a lower layer (of the appropriate scale), upscale ×2, add the out‐
put of an even lower layer, and finally upscale ×8. It is even possible to scale up
beyond the size of the original image: this can be used to increase the resolution of an
image, which is a technique called <i>super-resolution.</i>