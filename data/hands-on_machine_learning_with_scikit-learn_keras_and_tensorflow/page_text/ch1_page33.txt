                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                           No Free Lunch Theorem                      
                                                                      
           A model is a simplified version of the observations. The simplifications are meant to
           discard the superfluous details that are unlikely to generalize to new instances. To
           decide what data to discard and what data to keep, you must make assumptions. For
           example, a linear model makes the assumption that the data is fundamentally linear
           and that the distance between the instances and the straight line is just noise, which
           can safely be ignored.                                     
           In a famous 1996 paper,11 David Wolpert demonstrated that if you make absolutely
           no assumption about the data, then there is no reason to prefer one model over any
           other. This is called the No Free Lunch (NFL) theorem. For some datasets the best
           model is a linear model, while for other datasets it is a neural network. There is no
           model that is a priori guaranteed to work better (hence the name of the theorem). The
           only way to know for sure which model is best is to evaluate them all. Since this is not
           possible, in practice you make some reasonable assumptions about the data and eval‐
           uate only a few reasonable models. For example, for simple tasks you may evaluate
           linear models with various levels of regularization, and for a complex problem you
           may evaluate various neural networks.                      
          Exercises                                                   
                                                                      
                                                                      
          In this chapter we have covered some of the most important concepts in Machine
          Learning. In the next chapters we will dive deeper and write more code, but before we
          do, make sure you know how to answer the following questions:
           1. How would you define Machine Learning?                  
                                                                      
           2. Can you name four types of problems where it shines?    
           3. What is a labeled training set?                         
           4. What are the two most common supervised tasks?          
           5. Can you name four common unsupervised tasks?            
                                                                      
           6. What type of Machine Learning algorithm would you use to allow a robot to
            walk in various unknown terrains?                         
           7. What type of algorithm would you use to segment your customers into multiple
            groups?                                                   
           8. Would you frame the problem of spam detection as a supervised learning prob‐
            lem or an unsupervised learning problem?                  
                                                                      
                                                                      
          11 David Wolpert, “The Lack of A Priori Distinctions Between Learning Algorithms,” Neural Computation 8, no.
           7 (1996): 1341–1390.                                       