                                                                      
                                                                      
                                                                      
                                                                      
             to serialize each image), and the label.11 Then use tf.data to create an efficient
            dataset for each set. Finally, use a Keras model to train these datasets, including a
            preprocessing layer to standardize each input feature. Try to make the input
            pipeline as efficient as possible, using TensorBoard to visualize profiling data.
                                                                      
          10. In this exercise you will download a dataset, split it, create a tf.data.Dataset to
            load it and preprocess it efficiently, then build and train a binary classification
            model containing an Embedding layer:                      
             a. Download the Large Movie Review Dataset, which contains 50,000 movies
              reviews from the Internet Movie Database. The data is organized in two direc‐
              tories, train and test, each containing a pos subdirectory with 12,500 positive
              reviews and a neg subdirectory with 12,500 negative reviews. Each review is
              stored in a separate text file. There are other files and folders (including pre‐
              processed bag-of-words), but we will ignore them in this exercise.
            b. Split the test set into a validation set (15,000) and a test set (10,000).
             c. Use tf.data to create an efficient dataset for each set.
                                                                      
            d. Create a binary classification model, using a TextVectorization layer to pre‐
              process each review. If the TextVectorization layer is not yet available (or if
              you like a challenge), try to create your own custom preprocessing layer: you
              can use the functions in the tf.strings package, for example lower() to
              make everything lowercase, regex_replace() to replace punctuation with
              spaces, and split() to split words on spaces. You should use a lookup table to
              output word indices, which must be prepared in the adapt() method.
             e. Add an Embedding layer and compute the mean embedding for each review,
              multiplied by the square root of the number of words (see Chapter 16). This
              rescaled mean embedding can then be passed to the rest of your model.
             f. Train the model and see what accuracy you get. Try to optimize your pipelines
              to make training as fast as possible.                   
            g. Use TFDS to load the same dataset more easily: tfds.load("imdb_reviews").
                                                                      
          Solutions to these exercises are available in Appendix A.   
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
          11 For large images, you could use tf.io.encode_jpeg() instead. This would save a lot of space, but it would
           lose a bit of image quality.                               