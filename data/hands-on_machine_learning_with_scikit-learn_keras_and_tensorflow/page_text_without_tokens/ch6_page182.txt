                                                                      
                                                                      
                                                                      
                                                                      
          min_samples_leaf but expressed as a fraction of the total number of weighted
          instances), max_leaf_nodes (the maximum number of leaf nodes), and max_features
          (the maximum number of features that are evaluated for splitting at each node).
          Increasing min_* hyperparameters or reducing max_* hyperparameters will regularize
          the model.                                                  
                                                                      
                   Other algorithms work by first training the Decision Tree without
                   restrictions, then pruning (deleting) unnecessary nodes. A node
                   whose children are all leaf nodes is considered unnecessary if the
                   purity improvement it provides is not statistically significant. Stan‐
                   dard statistical tests, such as the χ2 test (chi-squared test), are used
                   to estimate the probability that the improvement is purely the
                   result of chance (which is called the null hypothesis). If this proba‐
                   bility, called the p-value, is higher than a given threshold (typically
                   5%, controlled by a hyperparameter), then the node is considered
                   unnecessary and its children are deleted. The pruning continues
                   until all unnecessary nodes have been pruned.      
          Figure 6-3 shows two Decision Trees trained on the moons dataset (introduced in
          Chapter 5). On the left the Decision Tree is trained with the default hyperparameters
          (i.e., no restrictions), and on the right it’s trained with min_samples_leaf=4. It is
          quite obvious that the model on the left is overfitting, and the model on the right will
          probably generalize better.                                 
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
          Figure 6-3. Regularization using min_samples_leaf           
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      