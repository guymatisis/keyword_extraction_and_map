                                                                      
                                                                      
                                                                      
                                                                      
          The most common step function used in Perceptrons is the Heaviside step function
          (see Equation 10-1). Sometimes the sign function is used instead.
                                                                      
            Equation 10-1. Common step functions used in Perceptrons (assuming threshold =
            0)                                                        
                                    −1 if z<0                         
                     0 if z<0                                         
            heaviside z =     sgn z = 0 if z=0                        
                     1 if z≥0                                         
                                    +1 if z>0                         
          A single TLU can be used for simple linear binary classification. It computes a linear
          combination of the inputs, and if the result exceeds a threshold, it outputs the posi‐
          tive class. Otherwise it outputs the negative class (just like a Logistic Regression or
          linear SVM classifier). You could, for example, use a single TLU to classify iris flowers
          based on petal length and width (also adding an extra bias feature x = 1, just like we
                                                  0                   
          did in previous chapters). Training a TLU in this case means finding the right values
          for w , w , and w (the training algorithm is discussed shortly).
             0 1    2                                                 
          A Perceptron is simply composed of a single layer of TLUs,7 with each TLU connected
          to all the inputs. When all the neurons in a layer are connected to every neuron in the
          previous layer (i.e., its input neurons), the layer is called a fully connected layer, or a
          dense layer. The inputs of the Perceptron are fed to special passthrough neurons
          called input neurons: they output whatever input they are fed. All the input neurons
          form the input layer. Moreover, an extra bias feature is generally added (x = 1): it is
                                                     0                
          typically represented using a special type of neuron called a bias neuron, which out‐
          puts 1 all the time. A Perceptron with two inputs and three outputs is represented in
          Figure 10-5. This Perceptron can classify instances simultaneously into three different
          binary classes, which makes it a multioutput classifier.    
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
          7 The name Perceptron is sometimes used to mean a tiny network with a single TLU.