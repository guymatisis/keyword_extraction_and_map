                                                                      
                                                                      
                                                                      
                                                                      
           5. A custom loss function can be defined by writing a function or by subclassing the
            keras.losses.Loss class. When would you use each option?  
                                                                      
           6. Similarly, a custom metric can be defined in a function or a subclass of
            keras.metrics.Metric. When would you use each option?     
           7. When should you create a custom layer versus a custom model?
           8. What are some use cases that require writing your own custom training loop?
           9. Can custom Keras components contain arbitrary Python code, or must they be
            convertible to TF Functions?                              
                                                                      
          10. What are the main rules to respect if you want a function to be convertible to a
            TF Function?                                              
          11. When would you need to create a dynamic Keras model? How do you do that?
            Why not make all your models dynamic?                     
          12. Implement a custom layer that performs Layer Normalization (we will use this
            type of layer in Chapter 15):                             
             a. The build() method should define two trainable weights α and β, both of
              shape input_shape[-1:] and data type tf.float32. α should be initialized
              with 1s, and β with 0s.                                 
                                                                      
            b. The call() method should compute the mean μ and standard deviation σ of
              each instance’s features. For this, you can use tf.nn.moments(inputs,
              axes=-1, keepdims=True), which returns the mean μ and the variance σ2 of
              all instances (compute the square root of the variance to get the standard
              deviation). Then the function should compute and return α⊗(X - μ)/(σ + ε) +
              β, where ⊗ represents itemwise multiplication (*) and ε is a smoothing term
              (small constant to avoid division by zero, e.g., 0.001).
             c. Ensure that your custom layer produces the same (or very nearly the same)
              output as the keras.layers.LayerNormalization layer.    
          13. Train a model using a custom training loop to tackle the Fashion MNIST dataset
            (see Chapter 10).                                         
                                                                      
             a. Display the epoch, iteration, mean training loss, and mean accuracy over each
              epoch (updated at each iteration), as well as the validation loss and accuracy at
              the end of each epoch.                                  
            b. Try using a different optimizer with a different learning rate for the upper lay‐
              ers and the lower layers.                               
          Solutions to these exercises are available in Appendix A.   
                                                                      
                                                                      
                                                                      
                                                                      