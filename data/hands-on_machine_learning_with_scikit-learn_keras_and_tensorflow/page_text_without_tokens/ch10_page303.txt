                                                                      
                                                                      
                                                                      
                                                                      
                   If you want to convert sparse labels (i.e., class indices) to one-hot
                   vector labels, use the keras.utils.to_categorical() function. To
                   go the other way round, use the np.argmax() function with
                   axis=1.                                            
                                                                      
          Regarding the optimizer, "sgd" means that we will train the model using simple Sto‐
          chastic Gradient Descent. In other words, Keras will perform the backpropagation
          algorithm described earlier (i.e., reverse-mode autodiff plus Gradient Descent). We
          will discuss more efficient optimizers in Chapter 11 (they improve the Gradient
          Descent part, not the autodiff).                            
                                                                      
                   When using the SGD optimizer, it is important to tune the learning
                   rate. So, you will generally want to use optimizer=keras.optimiz
                   ers.SGD(lr=???) to set the learning rate, rather than opti
                   mizer="sgd", which defaults to lr=0.01.            
                                                                      
          Finally, since this is a classifier, it’s useful to measure its "accuracy" during training
          and evaluation.                                             
                                                                      
          Training and evaluating the model                           
                                                                      
          Now the model is ready to be trained. For this we simply need to call its fit()
          method:                                                     
            >>> history = model.fit(X_train, y_train, epochs=30,      
            ...           validation_data=(X_valid, y_valid))         
            ...                                                       
            Train on 55000 samples, validate on 5000 samples          
            Epoch 1/30                                                
            55000/55000 [======] - 3s 49us/sample - loss: 0.7218 - accuracy: 0.7660
                                   - val_loss: 0.4973 - val_accuracy: 0.8366
            Epoch 2/30                                                
            55000/55000 [======] - 2s 45us/sample - loss: 0.4840 - accuracy: 0.8327
                                   - val_loss: 0.4456 - val_accuracy: 0.8480
            [...]                                                     
            Epoch 30/30                                               
            55000/55000 [======] - 3s 53us/sample - loss: 0.2252 - accuracy: 0.9192
                                   - val_loss: 0.2999 - val_accuracy: 0.8926
          We pass it the input features (X_train) and the target classes (y_train), as well as the
          number of epochs to train (or else it would default to just 1, which would definitely
          not be enough to converge to a good solution). We also pass a validation set (this is
          optional). Keras will measure the loss and the extra metrics on this set at the end of
          each epoch, which is very useful to see how well the model really performs. If the per‐
          formance on the training set is much better than on the validation set, your model is