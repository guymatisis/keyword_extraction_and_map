                                                                      
                                                                      
                                                                      
                                                                      
          Figure 6-2 shows this Decision Tree’s decision boundaries. The thick vertical line rep‐
          resents the decision boundary of the root node (depth 0): petal length = 2.45 cm.
          Since the lefthand area is pure (only Iris setosa), it cannot be split any further. How‐
          ever, the righthand area is impure, so the depth-1 right node splits it at petal width =
          1.75 cm (represented by the dashed line). Since max_depth was set to 2, the Decision
          Tree stops right there. If you set max_depth to 3, then the two depth-2 nodes would
          each add another decision boundary (represented by the dotted lines).
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
          Figure 6-2. Decision Tree decision boundaries               
                                                                      
                  Model Interpretation: White Box Versus Black Box    
                                                                      
           Decision Trees are intuitive, and their decisions are easy to interpret. Such models are
           often called white box models. In contrast, as we will see, Random Forests or neural
           networks are generally considered black box models. They make great predictions,
           and you can easily check the calculations that they performed to make these predic‐
           tions; nevertheless, it is usually hard to explain in simple terms why the predictions
           were made. For example, if a neural network says that a particular person appears on
           a picture, it is hard to know what contributed to this prediction: did the model recog‐
           nize that person’s eyes? Their mouth? Their nose? Their shoes? Or even the couch
           that they were sitting on? Conversely, Decision Trees provide nice, simple classifica‐
           tion rules that can even be applied manually if need be (e.g., for flower classification).
                                                                      
          Estimating Class Probabilities                              
                                                                      
          A Decision Tree can also estimate the probability that an instance belongs to a partic‐
          ular class k. First it traverses the tree to find the leaf node for this instance, and then it
          returns the ratio of training instances of class k in this node. For example, suppose
          you have found a flower whose petals are 5 cm long and 1.5 cm wide. The