<i>Figure</i> <i>4-12.</i> <i>Generated</i> <i>nonlinear</i> <i>and</i> <i>noisy</i> <i>dataset</i>
Poly
Clearly, a straight line will never fit this data properly. So let’s use Scikit-Learn’s
nomialFeatures class to transform our training data, adding the square (second-
degree polynomial) of each feature in the training set as a new feature (in this case
there is just one feature):
<b>>>></b> <b>from</b> <b>sklearn.preprocessing</b> <b>import</b> PolynomialFeatures
<b>>>></b> poly_features = PolynomialFeatures(degree=2, include_bias=False)
<b>>>></b> X_poly = poly_features.fit_transform(X)
<b>>>></b> X[0]
array([-0.75275929])
<b>>>></b> X_poly[0]
array([-0.75275929, 0.56664654])
X_poly X
now contains the original feature of plus the square of this feature. Now you
can fit a LinearRegression model to this extended training data (Figure 4-13):
<b>>>></b> lin_reg = LinearRegression()
<b>>>></b> lin_reg.fit(X_poly, y)
<b>>>></b> lin_reg.intercept_, lin_reg.coef_
(array([1.78134581]), array([[0.93366893, 0.56456263]]))