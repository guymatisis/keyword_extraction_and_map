<i>Figure</i> <i>12-3.</i> <i>Custom</i> <i>model</i> <i>example:</i> <i>an</i> <i>arbitrary</i> <i>model</i> <i>with</i> <i>a</i> <i>custom</i> <i>ResidualBlock</i>
<i>layer</i> <i>containing</i> <i>a</i> <i>skip</i> <i>connection</i>
The inputs go through a first dense layer, then through a <i>residual</i> <i>block</i> composed of
two dense layers and an addition operation (as we will see in Chapter 14, a residual
block adds its inputs to its outputs), then through this same residual block three more
times, then through a second residual block, and the final result goes through a dense
output layer. Note that this model does not make much sense; it’s just an example to
illustrate the fact that you can easily build any kind of model you want, even one that
contains loops and skip connections. To implement this model, it is best to first create
ResidualBlock
a layer, since we are going to create a couple of identical blocks (and
we might want to reuse it in another model):
<b>class</b> <b>ResidualBlock(keras.layers.Layer):</b>
<b>def</b> <b>__init__(self,</b> n_layers, n_neurons, **kwargs):
super().__init__(**kwargs)
self.hidden = [keras.layers.Dense(n_neurons, activation="elu",
kernel_initializer="he_normal")
<b>for</b> _ <b>in</b> range(n_layers)]
<b>def</b> call(self, inputs):
Z = inputs
<b>for</b> layer <b>in</b> self.hidden:
Z = layer(Z)
<b>return</b> inputs + Z
This layer is a bit special since it contains other layers. This is handled transparently
hidden
by Keras: it automatically detects that the attribute contains trackable objects
(layers in this case), so their variables are automatically added to this layer’s list of