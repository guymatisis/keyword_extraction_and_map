<i>Figure</i> <i>17-10.</i> <i>Sparsity</i> <i>loss</i>
Given two discrete probability distributions <i>P</i> and <i>Q,</i> the KL divergence between
these distributions, noted <i>D</i> (P ∥ <i>Q),</i> can be computed using Equation 17-1.
KL
<i>Equation</i> <i>17-1.</i> <i>Kullback–Leibler</i> <i>divergence</i>
<i>P</i> <i>i</i>
<i>D</i> <i>P</i> ∥ <i>Q</i> = <largefont>∑</largefont> <i>P</i> <i>i</i> log
KL <i>Q</i> <i>i</i>
<i>i</i>
In our case, we want to measure the divergence between the target probability <i>p</i> that a
neuron in the coding layer will activate and the actual probability <i>q</i> (i.e., the mean
activation over the training batch). So the KL divergence simplifies to Equation 17-2.
<i>Equation</i> <i>17-2.</i> <i>KL</i> <i>divergence</i> <i>between</i> <i>the</i> <i>target</i> <i>sparsity</i> <i>p</i> <i>and</i> <i>the</i> <i>actual</i> <i>sparsity</i> <i>q</i>
<i>p</i> 1 − <i>p</i>
∥
<i>D</i> <i>p</i> <i>q</i> = <i>p</i> log + 1 − <i>p</i> log
KL <i>q</i> 1 − <i>q</i>
Once we have computed the sparsity loss for each neuron in the coding layer, we sum
up these losses and add the result to the cost function. In order to control the relative
importance of the sparsity loss and the reconstruction loss, we can multiply the spar‐
sity loss by a sparsity weight hyperparameter. If this weight is too high, the model will
stick closely to the target sparsity, but it may not reconstruct the inputs properly,
making the model useless. Conversely, if it is too low, the model will mostly ignore
the sparsity objective and will not learn any interesting features.