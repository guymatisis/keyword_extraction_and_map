Keras will take care of variable persistence seamlessly; no action is
required.
When you define a metric using a simple function, Keras automatically calls it for
each batch, and it keeps track of the mean during each epoch, just like we did man‐
ually. So the only benefit of our HuberMetric class is that the threshold will be saved.
But of course, some metrics, like precision, cannot simply be averaged over batches:
in those cases, there’s no other option than to implement a streaming metric.
Now that we have built a streaming metric, building a custom layer will seem like a
walk in the park!
<header><largefont><b>Custom</b></largefont> <largefont><b>Layers</b></largefont></header>
You may occasionally want to build an architecture that contains an exotic layer for
which TensorFlow does not provide a default implementation. In this case, you will
need to create a custom layer. Or you may simply want to build a very repetitive
architecture, containing identical blocks of layers repeated many times, and it would
be convenient to treat each block of layers as a single layer. For example, if the model
is a sequence of layers A, B, C, A, B, C, A, B, C, then you might want to define a cus‐
tom layer D containing layers A, B, C, so your model would then simply be D, D, D.
Let’s see how to build custom layers.
keras.layers.Flatten keras.lay
First, some layers have no weights, such as or
ers.ReLU . If you want to create a custom layer without any weights, the simplest
keras.layers.Lambda
option is to write a function and wrap it in a layer. For exam‐
ple, the following layer will apply the exponential function to its inputs:
exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))
This custom layer can then be used like any other layer, using the Sequential API, the
Functional API, or the Subclassing API. You can also use it as an activation function
activation=tf.exp activation=keras.activations.exponen
(or you could use ,
tial , or simply activation="exponential" ). The exponential layer is sometimes
used in the output layer of a regression model when the values to predict have very
different scales (e.g., 0.001, 10., 1,000.).
As you’ve probably guessed by now, to build a custom stateful layer (i.e., a layer with
weights), you need to create a subclass of the keras.layers.Layer class. For exam‐
Dense
ple, the following class implements a simplified version of the layer: