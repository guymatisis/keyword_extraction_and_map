<header><largefont><b>Computational</b></largefont> <largefont><b>Complexity</b></largefont></header>
LinearSVC liblinear
The class is based on the library, which implements an opti‐
mized algorithm for linear SVMs.1 It does not support the kernel trick, but it scales
almost linearly with the number of training instances and the number of features. Its
training time complexity is roughly <i>O(m</i> × <i>n).</i>
The algorithm takes longer if you require very high precision. This is controlled by
the tolerance hyperparameter ϵ (called tol in Scikit-Learn). In most classification
tasks, the default tolerance is fine.
SVC libsvm
The class is based on the library, which implements an algorithm that
supports the kernel trick. 2 The training time complexity is usually between <i>O(m</i> 2 × <i>n)</i>
and <i>O(m3</i> × <i>n).</i> Unfortunately, this means that it gets dreadfully slow when the num‐
ber of training instances gets large (e.g., hundreds of thousands of instances). This
algorithm is perfect for complex small or medium-sized training sets. It scales well
with the number of features, especially with <i>sparse</i> <i>features</i> (i.e., when each instance
has few nonzero features). In this case, the algorithm scales roughly with the average
number of nonzero features per instance. Table 5-1 compares Scikit-Learn’s SVM
classification classes.
<i>Table</i> <i>5-1.</i> <i>Comparison</i> <i>of</i> <i>Scikit-Learn</i> <i>classes</i> <i>for</i> <i>SVM</i> <i>classification</i>
<b>Class</b> <b>Timecomplexity</b> <b>Out-of-coresupport</b> <b>Scalingrequired</b> <b>Kerneltrick</b>
LinearSVC O(m×n) No Yes No
SGDClassifier O(m×n) Yes Yes No
SVC O(m²×n)toO(m³×n) No Yes Yes
<header><largefont><b>SVM</b></largefont> <largefont><b>Regression</b></largefont></header>
As mentioned earlier, the SVM algorithm is versatile: not only does it support linear
and nonlinear classification, but it also supports linear and nonlinear regression. To
use SVMs for regression instead of classification, the trick is to reverse the objective:
instead of trying to fit the largest possible street between two classes while limiting
margin violations, SVM Regression tries to fit as many instances as possible <i>on</i> the
street while limiting margin violations (i.e., instances <i>off</i> the street). The width of the
ϵ
street is controlled by a hyperparameter, . Figure 5-10 shows two linear SVM
1 Chih-JenLinetal.,“ADualCoordinateDescentMethodforLarge-ScaleLinearSVM,”Proceedingsofthe25th
<i>InternationalConferenceonMachineLearning(2008):408–415.</i>
2 JohnPlatt,“SequentialMinimalOptimization:AFastAlgorithmforTrainingSupportVectorMachines”
(MicrosoftResearchtechnicalreport,April21,1998),https://www.microsoft.com/en-us/research/wp-content/
<i>uploads/2016/02/tr-98-14.pdf.</i>