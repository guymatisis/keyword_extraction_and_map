label.11
to serialize each image), and the Then use tf.data to create an efficient
dataset for each set. Finally, use a Keras model to train these datasets, including a
preprocessing layer to standardize each input feature. Try to make the input
pipeline as efficient as possible, using TensorBoard to visualize profiling data.
tf.data.Dataset
10. In this exercise you will download a dataset, split it, create a to
load it and preprocess it efficiently, then build and train a binary classification
Embedding
model containing an layer:
a. Download the Large Movie Review Dataset, which contains 50,000 movies
reviews from the Internet Movie Database. The data is organized in two direc‐
tories, <i>train</i> and <i>test,</i> each containing a <i>pos</i> subdirectory with 12,500 positive
reviews and a <i>neg</i> subdirectory with 12,500 negative reviews. Each review is
stored in a separate text file. There are other files and folders (including pre‐
processed bag-of-words), but we will ignore them in this exercise.
b. Split the test set into a validation set (15,000) and a test set (10,000).
c. Use tf.data to create an efficient dataset for each set.
TextVectorization
d. Create a binary classification model, using a layer to pre‐
process each review. If the TextVectorization layer is not yet available (or if
you like a challenge), try to create your own custom preprocessing layer: you
tf.strings lower()
can use the functions in the package, for example to
make everything lowercase, regex_replace() to replace punctuation with
split()
spaces, and to split words on spaces. You should use a lookup table to
output word indices, which must be prepared in the adapt() method.
Embedding
e. Add an layer and compute the mean embedding for each review,
multiplied by the square root of the number of words (see Chapter 16). This
rescaled mean embedding can then be passed to the rest of your model.
f. Train the model and see what accuracy you get. Try to optimize your pipelines
to make training as fast as possible.
tfds.load("imdb_reviews")
g. Use TFDS to load the same dataset more easily: .
Solutions to these exercises are available in Appendix A.
tf.io.encode_jpeg()
11 Forlargeimages,youcoulduse instead.Thiswouldsavealotofspace,butitwould
loseabitofimagequality.