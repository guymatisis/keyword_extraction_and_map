<header><largefont><b>Exercises</b></largefont></header>
1. What are the main tasks that autoencoders are used for?
2. Suppose you want to train a classifier, and you have plenty of unlabeled training
data but only a few thousand labeled instances. How can autoencoders help?
How would you proceed?
3. If an autoencoder perfectly reconstructs the inputs, is it necessarily a good
autoencoder? How can you evaluate the performance of an autoencoder?
4. What are undercomplete and overcomplete autoencoders? What is the main risk
of an excessively undercomplete autoencoder? What about the main risk of an
overcomplete autoencoder?
5. How do you tie weights in a stacked autoencoder? What is the point of doing so?
6. What is a generative model? Can you name a type of generative autoencoder?
7. What is a GAN? Can you name a few tasks where GANs can shine?
8. What are the main difficulties when training GANs?
9. Try using a denoising autoencoder to pretrain an image classifier. You can use
MNIST (the simplest option), or a more complex image dataset such as CIFAR10
if you want a bigger challenge. Regardless of the dataset you’re using, follow these
steps:
• Split the dataset into a training set and a test set. Train a deep denoising
autoencoder on the full training set.
• Check that the images are fairly well reconstructed. Visualize the images that
most activate each neuron in the coding layer.
• Build a classification DNN, reusing the lower layers of the autoencoder. Train
it using only 500 images from the training set. Does it perform better with or
without pretraining?
10. Train a variational autoencoder on the image dataset of your choice, and use it to
generate images. Alternatively, you can try to find an unlabeled dataset that you
are interested in and see if you can generate new samples.
11. Train a DCGAN to tackle the image dataset of your choice, and use it to generate
images. Add experience replay and see if this helps. Turn it into a conditional
GAN where you can control the generated class.
Solutions to these exercises are available in Appendix A.