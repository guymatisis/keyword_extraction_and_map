paper10
groundbreaking that introduced the <i>backpropagation</i> training algorithm,
which is still used today. In short, it is Gradient Descent (introduced in Chapter 4)
using an efficient technique for computing the gradients automatically: 11 in just two
passes through the network (one forward, one backward), the backpropagation algo‐
rithm is able to compute the gradient of the network’s error with regard to every sin‐
gle model parameter. In other words, it can find out how each connection weight and
each bias term should be tweaked in order to reduce the error. Once it has these gra‐
dients, it just performs a regular Gradient Descent step, and the whole process is
repeated until the network converges to the solution.
Automatically computing gradients is called <i>automatic</i> <i>differentia‐</i>
<i>tion,</i> or <i>autodiff.</i> There are various autodiff techniques, with differ‐
ent pros and cons. The one used by backpropagation is called
<i>reverse-mode</i> <i>autodiff.</i> It is fast and precise, and is well suited when
the function to differentiate has many variables (e.g., connection
weights) and few outputs (e.g., one loss). If you want to learn more
about autodiff, check out Appendix D.
Let’s run through this algorithm in a bit more detail:
• It handles one mini-batch at a time (for example, containing 32 instances each),
and it goes through the full training set multiple times. Each pass is called an
<i>epoch.</i>
• Each mini-batch is passed to the network’s input layer, which sends it to the first
hidden layer. The algorithm then computes the output of all the neurons in this
layer (for every instance in the mini-batch). The result is passed on to the next
layer, its output is computed and passed to the next layer, and so on until we get
the output of the last layer, the output layer. This is the <i>forward</i> <i>pass:</i> it is exactly
like making predictions, except all intermediate results are preserved since they
are needed for the backward pass.
• Next, the algorithm measures the network’s output error (i.e., it uses a loss func‐
tion that compares the desired output and the actual output of the network, and
returns some measure of the error).
• Then it computes how much each output connection contributed to the error.
This is done analytically by applying the <i>chain</i> <i>rule</i> (perhaps the most fundamen‐
tal rule in calculus), which makes this step fast and precise.
10 DavidRumelhartetal.“LearningInternalRepresentationsbyErrorPropagation,”(DefenseTechnicalInfor‐
mationCentertechnicalreport,September1985).
11 Thistechniquewasactuallyindependentlyinventedseveraltimesbyvariousresearchersindifferentfields,
startingwithPaulWerbosin1974.