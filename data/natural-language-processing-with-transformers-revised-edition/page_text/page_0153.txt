There is a separate score in ROUGE to measure the longest common substring (LCS),
called ROUGE-L. The LCS can be calculated for any pair of strings. For example, the
LCS for “abab” and “abc” would be “ab”, and its the length would be 2. If we want to
compare this value between two samples we need to somehow normalize it because
otherwise a longer text would be at an advantage. To achieve this, the inventor of
ROUGE came up with an <i>F-score-like</i> scheme where the LCS is normalized with the
length of the reference and generated text, then the two normalized scores are mixed
together:
<i>LCS</i> <i>X,Y</i>
<i>R</i> =
<i>LCS</i>
<i>m</i>
<i>LCS</i> <i>X,Y</i>
<i>P</i> =
<i>LCS</i> <i>n</i>
2
1 + <i>β</i> <i>R</i> <i>P</i>
<i>LCS</i> <i>LCS</i>
<i>F</i> = ,where <i>β</i> = <i>P</i> /R
<i>LCS</i> <i>R</i> + <i>βP</i> <i>LCS</i> <i>LCS</i>
<i>LCS</i> <i>LCS</i>
That way the LCS score is properly normalized and can be compared across samples.
In the Datasets implementation, two variations of ROUGE are calculated: one cal‐
culates the score per sentence and averages it for the summaries (ROUGE-L), and the
other calculates it directly over the whole summary (ROUGE-Lsum).
We can load the metric as follows:
rouge_metric = load_metric("rouge")
We already generated a set of summaries with GPT-2 and the other models, and now
we have a metric to compare the summaries systematically. Let’s apply the ROUGE
score to all the summaries generated by the models:
reference = dataset["train"][1]["highlights"]
records = []
rouge_names = ["rouge1", "rouge2", "rougeL", "rougeLsum"]
<b>for</b> model_name <b>in</b> summaries:
rouge_metric.add(prediction=summaries[model_name], reference=reference)
score = rouge_metric.compute()
rouge_dict = dict((rn, score[rn].mid.fmeasure) <b>for</b> rn <b>in</b> rouge_names)
records.append(rouge_dict)
pd.DataFrame.from_records(records, index=summaries.keys())
<b>rouge1</b> <b>rouge2</b> <b>rougeL</b> <b>rougeLsum</b>
0.303571 0.090909 0.214286 0.232143
<b>baseline</b>
<b>gpt2</b> 0.187500 0.000000 0.125000 0.187500