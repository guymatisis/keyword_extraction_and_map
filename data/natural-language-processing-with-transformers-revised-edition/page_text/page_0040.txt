[batch_size, n_tokens]
As we can see, the resulting tensor has the shape . Now that
we have the encodings as a tensor, the final step is to place them on the same device
as the model and pass the inputs as follows:
inputs = {k:v.to(device) <b>for</b> k,v <b>in</b> inputs.items()}
<b>with</b> torch.no_grad():
outputs = model(**inputs)
<b>print(outputs)</b>
BaseModelOutput(last_hidden_state=tensor([[[-0.1565, -0.1862, 0.0528, ...,
-0.1188, 0.0662, 0.5470],
[-0.3575, -0.6484, -0.0618, ..., -0.3040, 0.3508, 0.5221],
[-0.2772, -0.4459, 0.1818, ..., -0.0948, -0.0076, 0.9958],
[-0.2841, -0.3917, 0.3753, ..., -0.2151, -0.1173, 1.0526],
[ 0.2661, -0.5094, -0.3180, ..., -0.4203, 0.0144, -0.2149],
[ 0.9441, 0.0112, -0.4714, ..., 0.1439, -0.7288, -0.1619]]],
device='cuda:0'), hidden_states=None, attentions=None)
Here we’ve used the torch.no_grad() context manager to disable the automatic cal‐
culation of the gradient. This is useful for inference since it reduces the memory foot‐
print of the computations. Depending on the model configuration, the output can
contain several objects, such as the hidden states, losses, or attentions, arranged in a
class similar to a namedtuple in Python. In our example, the model output is an
BaseModelOutput
instance of , and we can simply access its attributes by name. The
current model returns only one attribute, which is the last hidden state, so let’s exam‐
ine its shape:
outputs.last_hidden_state.size()
torch.Size([1, 6, 768])
Looking at the hidden state tensor, we see that it has the shape [batch_size,
n_tokens, hidden_dim]
. In other words, a 768-dimensional vector is returned for
each of the 6 input tokens. For classification tasks, it is common practice to just use
the hidden state associated with the [CLS] token as the input feature. Since this token
appears at the start of each sequence, we can extract it by simply indexing into
outputs.last_hidden_state as follows:
outputs.last_hidden_state[:,0].size()
torch.Size([1, 768])
Now we know how to get the last hidden state for a single string; let’s do the same for
the whole dataset by creating a new hidden_state column that stores all these vec‐
map() DatasetDict
tors. As we did with the tokenizer, we’ll use the method of to
extract all the hidden states in one go. The first thing we need to do is wrap the previ‐
ous steps in a processing function:
<b>def</b> extract_hidden_states(batch):
<i>#</i> <i>Place</i> <i>model</i> <i>inputs</i> <i>on</i> <i>the</i> <i>GPU</i>
inputs = {k:v.to(device) <b>for</b> k,v <b>in</b> batch.items()