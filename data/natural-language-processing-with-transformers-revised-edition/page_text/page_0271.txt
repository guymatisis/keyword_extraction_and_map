zero-shot pipeline excels at those since it does not require any examples to learn
from.
You might notice a slight paradox in this section: although we talk
about dealing with no labels, we still use the validation and test
sets. We use them to showcase different techniques and to make
the results comparable between them. Even in a real use case, it
makes sense to gather a handful of labeled examples to run some
quick evaluations. The important point is that we did not adapt the
parameters of the model with the data; instead, we just adapted
some hyperparameters.
If you find it difficult to get good results on your own dataset, here are a few things
you can do to improve the zero-shot pipeline:
• The way the pipeline works makes it very sensitive to the names of the labels. If
the names don’t make much sense or are not easily connected to the texts, the
pipeline will likely perform poorly. Either try using different names or use several
names in parallel and aggregate them in an extra step.
• Another thing you can improve is the form of the hypothesis. By default it is
hypothesis="This is example is about {}" , but you can pass any other text
to the pipeline. Depending on the use case, this might improve the performance.
Let’s now turn to the regime where we have a few labeled examples we can use to
train a model.
<header><largefont><b>Working</b></largefont> <largefont><b>with</b></largefont> <largefont><b>a</b></largefont> <largefont><b>Few</b></largefont> <largefont><b>Labels</b></largefont></header>
In most NLP projects, you’ll have access to at least a few labeled examples. The labels
might come directly from a client or cross-company team, or you might decide to just
sit down and annotate a few examples yourself. Even for the previous approach, we
needed a few labeled examples to evaluate how well the zero-shot approach worked.
In this section, we’ll have a look at how we can best leverage the few, precious labeled
examples that we have. Let’s start by looking at a technique known as data augmenta‐
tion that can help us multiply the little labeled data that we have.
<header><largefont><b>Data</b></largefont> <largefont><b>Augmentation</b></largefont></header>
One simple but effective way to boost the performance of text classifiers on small
datasets is to apply <i>data</i> <i>augmentation</i> techniques to generate new training examples
from the existing ones. This is a common strategy in computer vision, where images
are randomly perturbed without changing the meaning of the data (e.g., a slightly