<i>Figure</i> <i>11-15.</i> <i>The</i> <i>model</i> <i>architecture</i> <i>and</i> <i>pretraining</i> <i>strategies</i> <i>for</i> <i>LayoutLMv2</i> <i>(cour‐</i>
<i>tesy</i> <i>of</i> <i>Yang</i> <i>Xu)</i>
<b>DALL·E</b>
A model that combines vision and text for <i>generative</i> tasks is DALL·E.18 It uses the
GPT architecture and autoregressive modeling to generate images from text. Inspired
by iGPT, it regards the words and pixels as one sequence of tokens and is thus able to
continue generating an image from a text prompt, as shown in Figure 11-16.
18 A.Rameshetal.,“Zero-ShotText-to-ImageGeneration”,(2021).