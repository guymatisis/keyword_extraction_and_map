<header><largefont><b>CHAPTER</b></largefont> <largefont><b>12</b></largefont></header>
<header><largefont><b>A</b></largefont> <largefont><b>Language</b></largefont> <largefont><b>Model</b></largefont> <largefont><b>from</b></largefont> <largefont><b>Scratch</b></largefont></header>
We’re now ready to go deep…deep into deep learning! You already learned how to
train a basic neural network, but how do you go from there to creating state-of-the-
art models? In this part of the book, we’re going to uncover all of the mysteries, start‐
ing with language models.
You saw in Chapter 10 how to fine-tune a pretrained language model to build a text
classifier. In this chapter, we will explain exactly what is inside that model and what
an RNN is. First, let’s gather some data that will allow us to quickly prototype our var‐
ious models.
<header><largefont><b>The</b></largefont> <largefont><b>Data</b></largefont></header>
Whenever we start working on a new problem, we always first try to think of the sim‐
plest dataset we can that will allow us to try out methods quickly and easily, and inter‐
pret the results. When we started working on language modeling a few years ago, we
didn’t find any datasets that would allow for quick prototyping, so we made one. We
call it <i>Human</i> <i>Numbers,</i> and it simply contains the first 10,000 numbers written out in
English.
<b>JeremySays</b>
One of the most common practical mistakes I see even among
highly experienced practitioners is failing to use appropriate data‐
sets at appropriate times during the analysis process. In particular,
most people tend to start with datasets that are too big and too
complicated.