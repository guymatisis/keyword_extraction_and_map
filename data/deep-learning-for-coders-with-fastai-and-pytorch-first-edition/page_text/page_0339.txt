representations for rare words. However, this last issue is better handled by setting
min_freq; the default min_freq=3 means that any word appearing fewer than three
times is replaced with xxunk .
fastai can also numericalize your dataset using a vocab that you provide, by passing a
list of words as the vocab parameter.
Once we’ve created our Numericalize object, we can use it as if it were a function:
nums = num(toks)[:20]; nums
tensor([ 2, 8, 21, 28, 11, 90, 18, 59, 0, 45, 9, 351, 499, 11,
> 72, 533, 584, 146, 29, 12])
This time, our tokens have been converted to a tensor of integers that our model can
receive. We can check that they map back to the original text:
' '.join(num.vocab[o] <b>for</b> o <b>in</b> nums)
'xxbos xxmaj this movie , which i just xxunk at the video store , has apparently
> sit around for a'
Now that we have numbers, we need to put them in batches for our model.
<header><largefont><b>Putting</b></largefont> <largefont><b>Our</b></largefont> <largefont><b>Texts</b></largefont> <largefont><b>into</b></largefont> <largefont><b>Batches</b></largefont> <largefont><b>for</b></largefont> <largefont><b>a</b></largefont> <largefont><b>Language</b></largefont> <largefont><b>Model</b></largefont></header>
When dealing with images, we needed to resize them all to the same height and width
before grouping them together in a mini-batch so they could stack together efficiently
in a single tensor. Here it’s going to be a little different, because one cannot simply
resize text to a desired length. Also, we want our language model to read text in order,
so that it can efficiently predict what the next word is. This means each new batch
should begin precisely where the previous one left off.
Suppose we have the following text:
In this chapter, we will go back over the example of classifying movie reviews we stud‐
ied in chapter 1 and dig deeper under the surface. First we will look at the processing
steps necessary to convert text into numbers and how to customize it. By doing this,
we’ll have another example of the PreProcessor used in the data block API.
Then we will study how we build a language model and train it for a while.
The tokenization process will add special tokens and deal with punctuation to return
this text:
xxbos xxmaj in this chapter , we will go back over the example of classifying movie
reviews we studied in chapter 1 and dig deeper under the surface . xxmaj first we will
look at the processing steps necessary to convert text into numbers and how to cus‐
tomize it . xxmaj by doing this , we ‘ll have another example of the preprocessor used
in the data block xxup api . \n xxmaj then we will study how we build a language
model and train it for a while .