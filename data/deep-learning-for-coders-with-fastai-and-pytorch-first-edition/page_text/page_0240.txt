<i>MNIST</i>
50,000 28×28-pixel grayscale handwritten digits
<i>CIFAR10</i>
60,000 32×32-pixel color images in 10 classes
The problem was that the smaller datasets didn’t generalize effectively to the large
ImageNet dataset. The approaches that worked well on ImageNet generally had to be
developed and trained on ImageNet. This led to many people believing that only
researchers with access to giant computing resources could effectively contribute to
developing image classification algorithms.
We thought that seemed very unlikely to be true. We had never seen a study that
showed that ImageNet happens to be exactly the right size, and that other datasets
could not be developed that would provide useful insights. So we wanted to create a
new dataset that researchers could test their algorithms on quickly and cheaply, but
that would also provide insights likely to work on the full ImageNet dataset.
About three hours later, we had created Imagenette. We selected 10 classes from the
full ImageNet that looked very different from one another. As we had hoped, we were
able to quickly and cheaply create a classifier capable of recognizing these classes. We
then tried out a few algorithmic tweaks to see how they impacted Imagenette. We
found some that worked pretty well, and tested them on ImageNet as well—and we
were pleased to find that our tweaks worked well on ImageNet too!
There is an important message here: the dataset you are given is not necessarily the
dataset you want. It’s particularly unlikely to be the dataset that you want to do your
development and prototyping in. You should aim to have an iteration speed of no
more than a couple of minutes—that is, when you come up with a new idea you want
to try out, you should be able to train a model and see how it goes within a couple of
minutes. If it’s taking longer to do an experiment, think about how you could cut
down your dataset, or simplify your model, to improve your experimentation speed.
The more experiments you can do, the better!
Let’s get started with this dataset:
<b>from</b> <b>fastai.vision.all</b> <b>import</b> *
path = untar_data(URLs.IMAGENETTE)
First we’ll get our dataset into a DataLoaders object, using the <i>presizing</i> trick intro‐
duced in Chapter 5:
dblock = DataBlock(blocks=(ImageBlock(), CategoryBlock()),
get_items=get_image_files,
get_y=parent_label,
item_tfms=Resize(460),
batch_tfms=aug_transforms(size=224, min_scale=0.75))
dls = dblock.dataloaders(path, bs=64)