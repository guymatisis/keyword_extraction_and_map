Cells that begin with a ! do not contain Python code, but instead contain code that is
passed to your shell (bash, Windows PowerShell, etc.). If you are comfortable using
the command line, which we’ll discuss more in this book, you can of course simply
type these two lines (without the ! prefix) directly into your terminal. In this case, the
first line installs the voila library and application, and the second connects it to your
existing Jupyter notebook.
Voilà runs Jupyter notebooks just like the Jupyter notebook server you are using now
does, but it also does something very important: it removes all of the cell inputs, and
shows only output (including ipywidgets), along with your Markdown cells. So what’s
left is a web application! To view your notebook as a Voilà web application, replace
the word “notebooks” in your browser’s URL with “voila/render”. You will see the
same content as your notebook, but without any of the code cells.
Of course, you don’t need to use Voilà or ipywidgets. Your model is just a function
you can call ( pred,pred_idx,probs = learn.predict(img) ), so you can use it with
any framework, hosted on any platform. And you can take something you’ve prototy‐
ped in ipywidgets and Voilà and later convert it into a regular web application. We’re
showing you this approach in the book because we think it’s a great way for data sci‐
entists and other folks who aren’t web development experts to create applications
from their models.
We have our app; now let’s deploy it!
<header><largefont><b>Deploying</b></largefont> <largefont><b>Your</b></largefont> <largefont><b>App</b></largefont></header>
As you now know, you need a GPU to train nearly any useful deep learning model.
So, do you need a GPU to use that model in production? No! You almost certainly <i>do</i>
<i>not</i> <i>need</i> <i>a</i> <i>GPU</i> <i>to</i> <i>serve</i> <i>your</i> <i>model</i> <i>in</i> <i>production.</i> There are a few reasons for this:
• As we’ve seen, GPUs are useful only when they do lots of identical work in paral‐
lel. If you’re doing (say) image classification, you’ll normally be classifying just
one user’s image at a time, and there isn’t normally enough work to do in a single
image to keep a GPU busy for long enough for it to be very efficient. So, a CPU
will often be more cost-effective.
• An alternative could be to wait for a few users to submit their images, and then
batch them up and process them all at once on a GPU. But then you’re asking
your users to wait, rather than getting answers straight away! And you need a
high-volume site for this to be workable. If you do need this functionality, you
can use a tool such as Microsoft’s ONNX Runtime or AWS SageMaker.
• The complexities of dealing with GPU inference are significant. In particular, the
GPU’s memory will need careful manual management, and you’ll need a careful
queueing system to ensure you process only one batch at a time.