<b>Step3:Calculatetheloss</b>
We calculate the loss as follows:
loss = mse(preds, speed)
loss
tensor(25823.8086, grad_fn=<MeanBackward0>)
Our goal is now to improve this. To do that, we’ll need to know the gradients.
<b>Step4:Calculatethegradients</b>
The next step is to calculate the gradients, or an approximation of how the parame‐
ters need to change:
loss.backward()
params.grad
tensor([-53195.8594, -3419.7146, -253.8908])
params.grad * 1e-5
tensor([-0.5320, -0.0342, -0.0025])
We can use these gradients to improve our parameters. We’ll need to pick a learning
rate (we’ll discuss how to do that in practice in the next chapter; for now, we’ll just use
1e-5 or 0.00001):
params
tensor([-0.7658, -0.7506, 1.3525], requires_grad=True)
<b>Step5:Steptheweights</b>
Now we need to update the parameters based on the gradients we just calculated:
lr = 1e-5
params.data -= lr * params.grad.data
params.grad = None
<b>AlexisSays</b>
Understanding this bit depends on remembering recent history. To
calculate the gradients, we call backward on the loss . But this loss
was itself calculated by mse , which in turn took preds as an input,
which was calculated using f taking as an input params , which was
the object on which we originally called required_grads_ —which
is the original call that now allows us to call backward on loss.
This chain of function calls represents the mathematical composi‐
tion of functions, which enables PyTorch to use calculus’s chain
rule under the hood to calculate these gradients.