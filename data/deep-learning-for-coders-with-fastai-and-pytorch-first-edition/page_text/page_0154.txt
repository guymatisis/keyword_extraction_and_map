value of the parameter. When we know how our function will change, we know what
we need to do to make it smaller. This is the key to machine learning: having a way to
change the parameters of a function to make it smaller. Calculus provides us with a
computational shortcut, the derivative, which lets us directly calculate the gradients
of our functions.
One important thing to be aware of is that our function has lots of weights that we
need to adjust, so when we calculate the derivative, we won’t get back one number,
but lots of them—a gradient for every weight. But there is nothing mathematically
tricky here; you can calculate the derivative with respect to one weight and treat all
the other ones as constant, and then repeat that for each other weight. This is how all
of the gradients are calculated, for every weight.
We mentioned just now that you won’t have to calculate any gradients yourself. How
can that be? Amazingly enough, PyTorch is able to automatically compute the deriva‐
tive of nearly any function! What’s more, it does it very fast. Most of the time, it will
be at least as fast as any derivative function that you can create by hand. Let’s see an
example.
First, let’s pick a tensor value at which we want gradients:
xt = tensor(3.).requires_grad_()
Notice the special method requires_grad_? That’s the magical incantation we use to
tell PyTorch that we want to calculate gradients with respect to that variable at that
value. It is essentially tagging the variable, so PyTorch will remember to keep track of
how to compute gradients of the other direct calculations on it that you will ask for.
<b>AlexisSays</b>
This API might throw you off if you’re coming from math or phys‐
ics. In those contexts, the “gradient” of a function is just another
function (i.e., its derivative), so you might expect gradient-related
APIs to give you a new function. But in deep learning, “gradient”
usually means the <i>value</i> of a function’s derivative at a particular
argument value. The PyTorch API also puts the focus on the argu‐
ment, not the function you’re actually computing the gradients of.
It may feel backward at first, but it’s just a different perspective.
Now we calculate our function with that value. Notice how PyTorch prints not just
the value calculated, but also a note that it has a gradient function it’ll be using to cal‐
culate our gradients when needed:
yt = f(xt)
yt
tensor(9., grad_fn=<PowBackward0>)