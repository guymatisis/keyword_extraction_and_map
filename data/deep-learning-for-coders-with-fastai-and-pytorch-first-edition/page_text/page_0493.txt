<header><largefont><b>CHAPTER</b></largefont> <largefont><b>17</b></largefont></header>
<header><largefont><b>A</b></largefont> <largefont><b>Neural</b></largefont> <largefont><b>Net</b></largefont> <largefont><b>from</b></largefont> <largefont><b>the</b></largefont> <largefont><b>Foundations</b></largefont></header>
This chapter begins a journey where we will dig deep into the internals of the models
we used in the previous chapters. We will be covering many of the same things we’ve
seen before, but this time around we’ll be looking much more closely at the imple‐
mentation details, and much less closely at the practical issues of how and why things
are as they are.
We will build everything from scratch, using only basic indexing into a tensor. We’ll
write a neural net from the ground up, and then implement backpropagation man‐
ually so we know exactly what’s happening in PyTorch when we call loss.backward.
We’ll also see how to extend PyTorch with custom <i>autograd</i> functions that allow us to
specify our own forward and backward computations.
<header><largefont><b>Building</b></largefont> <largefont><b>a</b></largefont> <largefont><b>Neural</b></largefont> <largefont><b>Net</b></largefont> <largefont><b>Layer</b></largefont> <largefont><b>from</b></largefont> <largefont><b>Scratch</b></largefont></header>
Let’s start by refreshing our understanding of how matrix multiplication is used in a
basic neural network. Since we’re building everything up from scratch, we’ll use noth‐
ing but plain Python initially (except for indexing into PyTorch tensors), and then
replace the plain Python with PyTorch functionality after we’ve seen how to create it.
<header><largefont><b>Modeling</b></largefont> <largefont><b>a</b></largefont> <largefont><b>Neuron</b></largefont></header>
A neuron receives a given number of inputs and has an internal weight for each of
them. It sums those weighted inputs to produce an output and adds an inner bias. In
math, this can be written as
<i>n</i>
<largefont>∑</largefont>
<i>out</i> = <i>x</i> <i>w</i> + <i>b</i>
<i>i</i> <i>i</i>
<i>i</i> = 1