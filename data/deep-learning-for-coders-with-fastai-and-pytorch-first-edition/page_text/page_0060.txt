<header><largefont><b>The</b></largefont> <largefont><b>State</b></largefont> <largefont><b>of</b></largefont> <largefont><b>Deep</b></largefont> <largefont><b>Learning</b></largefont></header>
Let’s start by considering whether deep learning can be any good at the problem you
are looking to work on. This section provides a summary of the state of deep learning
at the start of 2020. However, things move very fast, and by the time you read this,
some of these constraints may no longer exist. We will try to keep the book’s website
up-to-date; in addition, a Google search for “what can AI do now” is likely to provide
current information.
<b>Computervision</b>
There are many domains in which deep learning has not been used to analyze images
yet, but those where it has been tried have nearly universally shown that computers
can recognize items in an image at least as well as people can—even specially trained
people, such as radiologists. This is known as <i>object</i> <i>recognition.</i> Deep learning is also
good at recognizing where objects in an image are, and can highlight their locations
and name each found object. This is known as <i>object</i> <i>detection</i> (in a variant of this
that we saw in Chapter 1, every pixel is categorized based on the kind of object it is
part of—this is called <i>segmentation).</i>
Deep learning algorithms are generally not good at recognizing images that are sig‐
nificantly different in structure or style from those used to train the model. For
instance, if there were no black-and-white images in the training data, the model may
do poorly on black-and-white images. Similarly, if the training data did not contain
hand-drawn images, the model will probably do poorly on hand-drawn images.
There is no general way to check which types of images are missing in your training
set, but we will show in this chapter some ways to try to recognize when unexpected
image types arise in the data when the model is being used in production (this is
known as checking for <i>out-of-domain</i> data).
One major challenge for object detection systems is that image labeling can be slow
and expensive. There is a lot of work at the moment going into tools to try to make
this labeling faster and easier, and to require fewer handcrafted labels to train accu‐
rate object detection models. One approach that is particularly helpful is to syntheti‐
cally generate variations of input images, such as by rotating them or changing their
brightness and contrast; this is called <i>data</i> <i>augmentation</i> and also works well for text
and other types of models. We will be discussing it in detail in this chapter.
Another point to consider is that although your problem might not look like a com‐
puter vision problem, it might be possible with a little imagination to turn it into one.
For instance, if what you are trying to classify are sounds, you might try converting
the sounds into images of their acoustic waveforms and then training a model on
those images.