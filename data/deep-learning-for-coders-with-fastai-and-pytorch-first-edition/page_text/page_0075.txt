Now that we have assembled our data in a format fit for model training, let’s train an
image classifier using it.
<header><largefont><b>Training</b></largefont> <largefont><b>Your</b></largefont> <largefont><b>Model,</b></largefont> <largefont><b>and</b></largefont> <largefont><b>Using</b></largefont> <largefont><b>It</b></largefont> <largefont><b>to</b></largefont> <largefont><b>Clean</b></largefont> <largefont><b>Your</b></largefont> <largefont><b>Data</b></largefont></header>
Time to use the same lines of code as in Chapter 1 to train our bear classifier. We
don’t have a lot of data for our problem (150 pictures of each sort of bear at most), so
to train our model, we’ll use RandomResizedCrop , an image size of 224 pixels, which is
fairly standard for image classification, and the default aug_transforms:
bears = bears.new(
item_tfms=RandomResizedCrop(224, min_scale=0.5),
batch_tfms=aug_transforms())
dls = bears.dataloaders(path)
We can now create our Learner and fine-tune it in the usual way:
learn = cnn_learner(dls, resnet18, metrics=error_rate)
learn.fine_tune(4)
<b>epoch</b> <b>train_loss</b> <b>valid_loss</b> <b>error_rate</b> <b>time</b>
0 1.235733 0.212541 0.087302 00:05
<b>epoch</b> <b>train_loss</b> <b>valid_loss</b> <b>error_rate</b> <b>time</b>
0 0.213371 0.112450 0.023810 00:05
1 0.173855 0.072306 0.023810 00:06
2 0.147096 0.039068 0.015873 00:06
3 0.123984 0.026801 0.015873 00:06