<i>Figure</i> <i>3-15.</i> <i>Event</i> <i>organized</i> <i>by</i> <i>the</i> <i>group</i> <i>Heart</i> <i>of</i> <i>Texas</i>
Disinformation often involves coordinated campaigns of inauthentic behavior. For
instance, fraudulent accounts may try to make it seem like many people hold a partic‐
ular viewpoint. While most of us like to think of ourselves as independent-minded, in
reality we evolved to be influenced by others in our in-group, and in opposition to
those in our out-group. Online discussions can influence our viewpoints, or alter the
range of what we consider acceptable viewpoints. Humans are social animals, and as
social animals, we are extremely influenced by the people around us. Increasingly,
radicalization occurs in online environments; so influence is coming from people in
the virtual space of online forums and social networks.
Disinformation through autogenerated text is a particularly significant issue, due to
the greatly increased capability provided by deep learning. We discuss this issue in
depth when we delve into creating language models in Chapter 10.
One proposed approach is to develop some form of digital signature, to implement it
in a seamless way, and to create norms that we should trust only content that has been
verified. The head of the Allen Institute on AI, Oren Etzioni, wrote such a proposal in
an article titled “How Will We Prevent AI-Based Forgery?”: “AI is poised to make
high-fidelity forgery inexpensive and automated, leading to potentially disastrous
consequences for democracy, security, and society. The specter of AI forgery means