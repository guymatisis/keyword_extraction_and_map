With this, we can remove another for loop in our matrix multiplication function.
Now, instead of multiplying a[i] with b[:,j], we can multiply a[i] with the whole
matrix b using broadcasting, and then sum the results:
<b>def</b> matmul(a,b):
ar,ac = a.shape
br,bc = b.shape
<b>assert</b> ac==br
c = torch.zeros(ar, bc)
<b>for</b> i <b>in</b> range(ar):
<i>#</i> <i>c[i,j]</i> <i>=</i> <i>(a[i,:]</i> <i>*</i> <i>b[:,j]).sum()</i> <i>#</i> <i>previous</i>
c[i] = (a[i ].unsqueeze(-1) * b).sum(dim=0)
<b>return</b> c
%timeit -n 20 t4 = matmul(m1,m2)
357 µs ± 7.2 µs per loop (mean ± std. dev. of 7 runs, 20 loops each)
We’re now 3,700 times faster than our first implementation! Before we move on, let’s
discuss the rules of broadcasting in a little more detail.
<b>Broadcastingrules</b>
When operating on two tensors, PyTorch compares their shapes elementwise. It starts
with the <i>trailing</i> <i>dimensions</i> and works its way backward, adding 1 when it meets
empty dimensions. Two dimensions are <i>compatible</i> when one of the following is true:
• They are equal.
• One of them is 1, in which case that dimension is broadcast to make it the same
as the other.
Arrays do not need to have the same number of dimensions. For example, if you have
a 256×256×3 array of RGB values, and you want to scale each color in the image by a
different value, you can multiply the image by a one-dimensional array with three
values. Lining up the sizes of the trailing axes of these arrays according to the broad‐
cast rules shows that they are compatible:
Image (3d tensor): 256 x 256 x 3
Scale (1d tensor): (1) (1) 3
Result (3d tensor): 256 x 256 x 3
However, a 2D tensor of size 256×256 isn’t compatible with our image:
Image (3d tensor): 256 x 256 x 3
Scale (1d tensor): (1) 256 x 256
Error